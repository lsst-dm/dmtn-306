name: CI

"on": [push, pull_request]

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0 # full history for metadata
          submodules: true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Python install
        run: |
          python -m pip install --upgrade pip
          python -m pip install "lander<2.0.0"

      - name: Login to Docker Hub
        uses: docker/login-action@v1
        with:
          username: sqrereadonly
          password: ${{ secrets.DOCKERHUB_SQREREADONLY_TOKEN }}

      - name: TeX build
        run: |
          docker run --rm -v `pwd`:/workspace -w /workspace lsstsqre/lsst-texmf:latest sh -c 'make'

      - name: Landing page upload
        if: ${{ github.event_name == 'push' }}
        env:
          LTD_PASSWORD: ${{ secrets.LTD_PASSWORD }}
          LTD_USERNAME: ${{ secrets.LTD_USERNAME }}
        run: |
          lander --upload --pdf DMTN-306.pdf --lsstdoc DMTN-306.tex --ltd-product dmtn-306 --author "Fabio Hernandez" --author "Mark G. Beckett" --author "Andrew Hanushevsky" --author "Tim Jenness" --author "Kian-Tat Lim" --author "Peter Love" --author "Timothy Noble" --author "Stephen R. Pietrowicz" --author "Wei Yang" --abstract "The sky images captured nightly by the camera on the Vera C. Rubin Observatory’s telescope will be processed across facilities on three continents. Data acquisition will occur at the observatory's location on Cerro Pachón in the Andes mountains of Chile. A first copy of the raw image data set is stored at the summit and immediately transmitted via dedicated network links to the archive center within the US Data Facility at SLAC National Accelerator Laboratory in California, USA and from there to two European facilities for processing and archiving purposes. Data products resulting from periodic image processing campaigns of the entire set of images collected since the beginning of the survey are made available to the scientific community in the form of data releases. In this paper we present an overall view of how we leverage the tools selected for managing the movement of data among the Rubin processing and serving facilities, including Rucio and FTS. We also present the tools we developed to integrate Rucio's data model and Rubin's Data Butler, the software abstraction layer that mediates all access to storage by pipeline tasks that implement science algorithms."

